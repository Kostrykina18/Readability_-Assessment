{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ON3Ut6rX4M6K",
        "outputId": "cfc1af6d-06c3-49cc-b3dd-baaf64c73d92"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.8/dist-packages (4.25.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.8.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.11.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.26.13)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.8/dist-packages (2.8.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from datasets) (1.3.5)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.18.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.8/dist-packages (from datasets) (0.70.14)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from datasets) (3.8.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (4.64.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from datasets) (1.21.6)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: dill<0.3.7 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.3.6)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.8/dist-packages (from datasets) (3.2.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (6.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from datasets) (21.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (2.25.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.11.1)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (2022.11.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.8.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (22.2.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (6.0.3)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (2.1.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.8.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->datasets) (3.0.9)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (1.26.13)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2022.7)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "DG1gJZvMbWiF"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import TensorDataset, Dataset, DataLoader, RandomSampler, SequentialSampler\n",
        "import torch.nn.functional as F\n",
        "from transformers import BertTokenizer,BertModel, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
        "from sklearn.model_selection import train_test_split\n",
        "from collections import defaultdict\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, classification_report,precision_score,accuracy_score,f1_score\n",
        "\n",
        "import logging \n",
        "logging.basicConfig(level = logging.ERROR)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "X_-fYu0SVt5O"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "b0HdZ8KmZ1XY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86,
          "referenced_widgets": [
            "cdada0b541f94eddaf1b0e9f23a9a9b9",
            "b717ec4370de402e8263a38ca4dd30aa",
            "1e0d8d6adc5e432dbbae1762f0140e99",
            "f37e55a4cc3b4e479beb4a07fbd49b11",
            "b4da6277f04c41a58443a8876e9badf6",
            "44206c0d371f4ac0aa03731e1b968258",
            "9bc9f30cde044beabebacbaa860d5dc9",
            "9f90adc8bb7c4be998836153a3898a54",
            "7f4d43fb3f7a4893ad43eaefde975e70",
            "9fbb0d43e5b34456855f5a2825a7fda3",
            "51aeceaa410e4b24a7595e5d569eb5ff"
          ]
        },
        "outputId": "5b4e642e-31a5-41ed-f832-92a6b81ec7e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.builder:Found cached dataset onestop_english (/root/.cache/huggingface/datasets/onestop_english/default/1.1.0/6b19eec5680862ad1cf1990e98b06a98d1fa4c85f3585dc4dfab93f52b89d9cf)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cdada0b541f94eddaf1b0e9f23a9a9b9"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"onestop_english\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "4IT4dgxvaQVE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e9e2f83-0dd5-4354-9ca4-41d9c7551baf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "wzJswkORZ1Xa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1db9034f-cae5-440a-a3aa-48c487ff89bc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 567\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "C64GQYapZ1Xb"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame(dataset['train'])\n",
        "df.columns = ['content', 'labels']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "J-2wocL5Z1Xb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "53de1467-d083-4f3a-fb56-fcd6ad0b76bb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               content  labels\n",
              "0    When you see the word Amazon, what’s the first...       0\n",
              "1    To tourists, Amsterdam still seems very libera...       0\n",
              "2    Anitta, a music star from Brazil, has millions...       0\n",
              "3    Google has made maps of the world’s highest mo...       0\n",
              "4    The auction of a Banksy painting that disappea...       0\n",
              "..                                                 ...     ...\n",
              "562  In typical bad-boyfriend style, Dan Sullivan w...       2\n",
              "563  Thousands of people protested on Australia’s b...       2\n",
              "564  1 Race engineer \\nA race engineer liaises betw...       2\n",
              "565  More than one million British workers might be...       2\n",
              "566  Low-income countries will remain on the front ...       2\n",
              "\n",
              "[567 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-21bdd38a-9aeb-4434-a781-4f0e8b72515a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>content</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>When you see the word Amazon, what’s the first...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>To tourists, Amsterdam still seems very libera...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Anitta, a music star from Brazil, has millions...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Google has made maps of the world’s highest mo...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The auction of a Banksy painting that disappea...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>562</th>\n",
              "      <td>In typical bad-boyfriend style, Dan Sullivan w...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>563</th>\n",
              "      <td>Thousands of people protested on Australia’s b...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>564</th>\n",
              "      <td>1 Race engineer \\nA race engineer liaises betw...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>565</th>\n",
              "      <td>More than one million British workers might be...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>566</th>\n",
              "      <td>Low-income countries will remain on the front ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>567 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-21bdd38a-9aeb-4434-a781-4f0e8b72515a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-21bdd38a-9aeb-4434-a781-4f0e8b72515a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-21bdd38a-9aeb-4434-a781-4f0e8b72515a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ke0Lh6MeZ1Xb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cee0bfda-aff7-4de6-c867-72aa37c3d707"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    189\n",
              "1    189\n",
              "2    189\n",
              "Name: labels, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "df.labels.value_counts()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_diff = df.labels.unique()\n",
        "diff = ['beginner','intermediate','advanced']\n",
        "\n",
        "label = dict(zip(num_diff, diff))\n",
        "\n",
        "diff = list(diff)\n"
      ],
      "metadata": {
        "id": "6fGQF4Na1RQv"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Difficulty'] = df.labels.replace(label)\n",
        "df.head()\n",
        "\n"
      ],
      "metadata": {
        "id": "8uKNqd-g2dx4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "5844e8e4-8834-4ec6-d190-d0731f02397a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             content  labels Difficulty\n",
              "0  When you see the word Amazon, what’s the first...       0   beginner\n",
              "1  To tourists, Amsterdam still seems very libera...       0   beginner\n",
              "2  Anitta, a music star from Brazil, has millions...       0   beginner\n",
              "3  Google has made maps of the world’s highest mo...       0   beginner\n",
              "4  The auction of a Banksy painting that disappea...       0   beginner"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-220d660d-349f-4da8-82d0-c02c9eaa44e8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>content</th>\n",
              "      <th>labels</th>\n",
              "      <th>Difficulty</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>When you see the word Amazon, what’s the first...</td>\n",
              "      <td>0</td>\n",
              "      <td>beginner</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>To tourists, Amsterdam still seems very libera...</td>\n",
              "      <td>0</td>\n",
              "      <td>beginner</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Anitta, a music star from Brazil, has millions...</td>\n",
              "      <td>0</td>\n",
              "      <td>beginner</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Google has made maps of the world’s highest mo...</td>\n",
              "      <td>0</td>\n",
              "      <td>beginner</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The auction of a Banksy painting that disappea...</td>\n",
              "      <td>0</td>\n",
              "      <td>beginner</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-220d660d-349f-4da8-82d0-c02c9eaa44e8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-220d660d-349f-4da8-82d0-c02c9eaa44e8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-220d660d-349f-4da8-82d0-c02c9eaa44e8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "soyLC1jrZ1Xi"
      },
      "source": [
        "Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "LryfcJVUZ1Xi"
      },
      "outputs": [],
      "source": [
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "G26lK1f9Z1Xi"
      },
      "outputs": [],
      "source": [
        "contraction_mapping = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
        "\n",
        "                           \"didn't\": \"did not\", \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
        "\n",
        "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
        "\n",
        "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
        "\n",
        "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
        "\n",
        "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
        "\n",
        "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
        "\n",
        "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
        "\n",
        "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
        "\n",
        "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
        "\n",
        "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
        "\n",
        "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
        "\n",
        "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
        "\n",
        "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
        "\n",
        "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
        "\n",
        "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
        "\n",
        "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
        "\n",
        "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
        "\n",
        "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
        "\n",
        "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
        "\n",
        "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
        "\n",
        "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
        "\n",
        "                           \"you're\": \"you are\", \"you've\": \"you have\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "wbXCLbTCZ1Xj"
      },
      "outputs": [],
      "source": [
        "\n",
        "def clean_text(text):\n",
        "    #text=' '.join([contraction_mapping[i] if i in contraction_mapping.keys() else i for i in text.split()])\n",
        "    text=re.sub(\"'s\",\"\",text)\n",
        "    if text.split()[0] == 'Intermediate':\n",
        "      text = ' '.join(text.split()[1:])\n",
        "    text=' '.join([i for i in text.split() if i.isalpha()])\n",
        "    text=re.sub('[^a-zA-Z]',\" \",text)\n",
        "\n",
        "    \n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "4zEhwFpmZ1Xj"
      },
      "outputs": [],
      "source": [
        "df['content'] = df['content'].apply(clean_text)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df[df['Difficulty']=='intermediate']\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "63gUSLbrjTqQ",
        "outputId": "d58858c7-eef3-4c94-ce6a-d62638c7c3f2"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               content  labels    Difficulty\n",
              "189  When you see the word whats the first thing yo...       1  intermediate\n",
              "190  To Amsterdam still seems very Recently the cit...       1  intermediate\n",
              "191  Brazils latest funk has won millions of fans b...       1  intermediate\n",
              "192  It has mapped the worlds highest the ocean the...       1  intermediate\n",
              "193  The controversial auction of a Banksy mural th...       1  intermediate\n",
              "..                                                 ...     ...           ...\n",
              "373  In typical Dan Sullivan was late to breakfast ...       1  intermediate\n",
              "374  Thousands of people protested on Australias be...       1  intermediate\n",
              "375  Race engineer A race engineer liaises between ...       1  intermediate\n",
              "376  More than one million British workers might be...       1  intermediate\n",
              "377  countries will continue to be the most affecte...       1  intermediate\n",
              "\n",
              "[189 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b66cbfac-d3c2-46fc-8d86-dc237f393367\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>content</th>\n",
              "      <th>labels</th>\n",
              "      <th>Difficulty</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>189</th>\n",
              "      <td>When you see the word whats the first thing yo...</td>\n",
              "      <td>1</td>\n",
              "      <td>intermediate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>190</th>\n",
              "      <td>To Amsterdam still seems very Recently the cit...</td>\n",
              "      <td>1</td>\n",
              "      <td>intermediate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>191</th>\n",
              "      <td>Brazils latest funk has won millions of fans b...</td>\n",
              "      <td>1</td>\n",
              "      <td>intermediate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>192</th>\n",
              "      <td>It has mapped the worlds highest the ocean the...</td>\n",
              "      <td>1</td>\n",
              "      <td>intermediate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>193</th>\n",
              "      <td>The controversial auction of a Banksy mural th...</td>\n",
              "      <td>1</td>\n",
              "      <td>intermediate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>373</th>\n",
              "      <td>In typical Dan Sullivan was late to breakfast ...</td>\n",
              "      <td>1</td>\n",
              "      <td>intermediate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>374</th>\n",
              "      <td>Thousands of people protested on Australias be...</td>\n",
              "      <td>1</td>\n",
              "      <td>intermediate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>375</th>\n",
              "      <td>Race engineer A race engineer liaises between ...</td>\n",
              "      <td>1</td>\n",
              "      <td>intermediate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>376</th>\n",
              "      <td>More than one million British workers might be...</td>\n",
              "      <td>1</td>\n",
              "      <td>intermediate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>377</th>\n",
              "      <td>countries will continue to be the most affecte...</td>\n",
              "      <td>1</td>\n",
              "      <td>intermediate</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>189 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b66cbfac-d3c2-46fc-8d86-dc237f393367')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b66cbfac-d3c2-46fc-8d86-dc237f393367 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b66cbfac-d3c2-46fc-8d86-dc237f393367');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "fFTQ9n1oALub",
        "outputId": "204d5a3b-57a3-4a6f-aa9f-d84f7c27b73c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               content  labels Difficulty\n",
              "0    When you see the word the first thing you thin...       0   beginner\n",
              "1    To Amsterdam still seems very Recently the May...       0   beginner\n",
              "2    a music star from has millions of but she is a...       0   beginner\n",
              "3    Google has made maps of the highest the ocean ...       0   beginner\n",
              "4    The auction of a Banksy painting that disappea...       0   beginner\n",
              "..                                                 ...     ...        ...\n",
              "562  In typical Dan Sullivan was late to breakfast ...       2   advanced\n",
              "563  Thousands of people protested on beaches again...       2   advanced\n",
              "564  Race engineer A race engineer liaises between ...       2   advanced\n",
              "565  More than one million British workers might be...       2   advanced\n",
              "566  countries will remain on the front line of cli...       2   advanced\n",
              "\n",
              "[567 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a1671bb1-f0d0-46ad-bcab-571e9ed15cb5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>content</th>\n",
              "      <th>labels</th>\n",
              "      <th>Difficulty</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>When you see the word the first thing you thin...</td>\n",
              "      <td>0</td>\n",
              "      <td>beginner</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>To Amsterdam still seems very Recently the May...</td>\n",
              "      <td>0</td>\n",
              "      <td>beginner</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>a music star from has millions of but she is a...</td>\n",
              "      <td>0</td>\n",
              "      <td>beginner</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Google has made maps of the highest the ocean ...</td>\n",
              "      <td>0</td>\n",
              "      <td>beginner</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The auction of a Banksy painting that disappea...</td>\n",
              "      <td>0</td>\n",
              "      <td>beginner</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>562</th>\n",
              "      <td>In typical Dan Sullivan was late to breakfast ...</td>\n",
              "      <td>2</td>\n",
              "      <td>advanced</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>563</th>\n",
              "      <td>Thousands of people protested on beaches again...</td>\n",
              "      <td>2</td>\n",
              "      <td>advanced</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>564</th>\n",
              "      <td>Race engineer A race engineer liaises between ...</td>\n",
              "      <td>2</td>\n",
              "      <td>advanced</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>565</th>\n",
              "      <td>More than one million British workers might be...</td>\n",
              "      <td>2</td>\n",
              "      <td>advanced</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>566</th>\n",
              "      <td>countries will remain on the front line of cli...</td>\n",
              "      <td>2</td>\n",
              "      <td>advanced</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>567 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a1671bb1-f0d0-46ad-bcab-571e9ed15cb5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a1671bb1-f0d0-46ad-bcab-571e9ed15cb5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a1671bb1-f0d0-46ad-bcab-571e9ed15cb5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "sentence lenth"
      ],
      "metadata": {
        "id": "7RpKchNhAOmR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mBjvofpbAu7z",
        "outputId": "3fa20f82-3dce-4e7b-c57c-c6894fde21b3"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sen_len = []\n",
        "for i in df['content']:\n",
        "  curr_sen_len = []\n",
        "  for j in sent_tokenize(i):\n",
        "    curr_sen_len.append(len(word_tokenize(j)))\n",
        "  mean_len = np.mean(curr_sen_len)\n",
        "  sen_len.append(mean_len)"
      ],
      "metadata": {
        "id": "A2sl3XLmAN1W"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sen_len[400:410]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bly-SkRtBqic",
        "outputId": "e17bcd0c-7e2a-4e7e-aaea-ad3b8727772c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[864.0, 661.0, 686.0, 830.0, 671.0, 665.0, 787.0, 842.0, 565.0, 733.0]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['mean_sentence_len'] = sen_len"
      ],
      "metadata": {
        "id": "hCwBvSPZCCE8"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "XHRPRek8CCHj",
        "outputId": "a1aa1fa0-5f5d-4d4b-ed50-9044403b9ca3"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               content  labels Difficulty  \\\n",
              "0    When you see the word the first thing you thin...       0   beginner   \n",
              "1    To Amsterdam still seems very Recently the May...       0   beginner   \n",
              "2    a music star from has millions of but she is a...       0   beginner   \n",
              "3    Google has made maps of the highest the ocean ...       0   beginner   \n",
              "4    The auction of a Banksy painting that disappea...       0   beginner   \n",
              "..                                                 ...     ...        ...   \n",
              "562  In typical Dan Sullivan was late to breakfast ...       2   advanced   \n",
              "563  Thousands of people protested on beaches again...       2   advanced   \n",
              "564  Race engineer A race engineer liaises between ...       2   advanced   \n",
              "565  More than one million British workers might be...       2   advanced   \n",
              "566  countries will remain on the front line of cli...       2   advanced   \n",
              "\n",
              "     mean_sentence_len  \n",
              "0                351.0  \n",
              "1                380.0  \n",
              "2                387.0  \n",
              "3                432.0  \n",
              "4                371.0  \n",
              "..                 ...  \n",
              "562              445.0  \n",
              "563              516.0  \n",
              "564              704.0  \n",
              "565              684.0  \n",
              "566              559.0  \n",
              "\n",
              "[567 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-27bf5309-e310-4ebb-83c9-d1c556b28d4b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>content</th>\n",
              "      <th>labels</th>\n",
              "      <th>Difficulty</th>\n",
              "      <th>mean_sentence_len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>When you see the word the first thing you thin...</td>\n",
              "      <td>0</td>\n",
              "      <td>beginner</td>\n",
              "      <td>351.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>To Amsterdam still seems very Recently the May...</td>\n",
              "      <td>0</td>\n",
              "      <td>beginner</td>\n",
              "      <td>380.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>a music star from has millions of but she is a...</td>\n",
              "      <td>0</td>\n",
              "      <td>beginner</td>\n",
              "      <td>387.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Google has made maps of the highest the ocean ...</td>\n",
              "      <td>0</td>\n",
              "      <td>beginner</td>\n",
              "      <td>432.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The auction of a Banksy painting that disappea...</td>\n",
              "      <td>0</td>\n",
              "      <td>beginner</td>\n",
              "      <td>371.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>562</th>\n",
              "      <td>In typical Dan Sullivan was late to breakfast ...</td>\n",
              "      <td>2</td>\n",
              "      <td>advanced</td>\n",
              "      <td>445.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>563</th>\n",
              "      <td>Thousands of people protested on beaches again...</td>\n",
              "      <td>2</td>\n",
              "      <td>advanced</td>\n",
              "      <td>516.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>564</th>\n",
              "      <td>Race engineer A race engineer liaises between ...</td>\n",
              "      <td>2</td>\n",
              "      <td>advanced</td>\n",
              "      <td>704.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>565</th>\n",
              "      <td>More than one million British workers might be...</td>\n",
              "      <td>2</td>\n",
              "      <td>advanced</td>\n",
              "      <td>684.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>566</th>\n",
              "      <td>countries will remain on the front line of cli...</td>\n",
              "      <td>2</td>\n",
              "      <td>advanced</td>\n",
              "      <td>559.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>567 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-27bf5309-e310-4ebb-83c9-d1c556b28d4b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-27bf5309-e310-4ebb-83c9-d1c556b28d4b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-27bf5309-e310-4ebb-83c9-d1c556b28d4b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cD3nhOWHAMMH"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "6xzX_kXnZ1Xj"
      },
      "outputs": [],
      "source": [
        "from transformers import BertTokenizer,BertModel, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "U6YWXpoUdJjh"
      },
      "outputs": [],
      "source": [
        "class DiffDataset(Dataset):\n",
        "    def __init__(self, contents, labels, features, tokenizer, max_len):\n",
        "        self.contents = contents\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.features = features\n",
        "        self.max_len = max_len\n",
        "  \n",
        "    def __len__(self):\n",
        "        return len(self.contents)\n",
        "  \n",
        "    def __getitem__(self, item):\n",
        "        content = str(self.contents[item])\n",
        "        labels = self.labels[item]\n",
        "        features = self.features[item]\n",
        "        # Tokenizing the texts, while also including special tokens \n",
        "        # for start and end of the text, as well as padding\n",
        "        encoding = self.tokenizer.encode_plus(\n",
        "          content,\n",
        "          add_special_tokens=True,\n",
        "          max_length=self.max_len,\n",
        "          return_token_type_ids=False,\n",
        "          pad_to_max_length=True,\n",
        "          return_attention_mask=True,\n",
        "          return_tensors='pt', # We return here the data as Pytorch Tensor\n",
        "        )\n",
        "\n",
        "        return {\n",
        "          'content': content,\n",
        "          'input_ids': encoding['input_ids'].flatten(),\n",
        "          'attention_mask': encoding['attention_mask'].flatten(),\n",
        "          'labels': torch.tensor(labels, dtype=torch.long), \n",
        "          'features': torch.tensor([features], dtype=torch.long)\n",
        "        }\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.tensor([[12, 23, 45]], dtype=torch.long).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lr58EsvsbiZo",
        "outputId": "82287a64-3648-40a0-b599-81aaa2a42281"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "vrKeldykjkst",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c2ec1fc-ff4d-4d56-e3e9-811abb390741"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "size of training set : 407\n",
            "size of validation set : 46\n",
            "size of test set : 114\n"
          ]
        }
      ],
      "source": [
        "df_temp, df_test = train_test_split(df, test_size=0.2, random_state=42)\n",
        "df_train, df_val = train_test_split(df_temp, test_size=0.1, random_state=42)\n",
        "\n",
        "print(\"size of training set : \" + str(df_train.shape[0]))\n",
        "print(\"size of validation set : \" + str(df_val.shape[0]))\n",
        "print(\"size of test set : \" + str(df_test.shape[0]))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "-zKVpipDbinP"
      },
      "outputs": [],
      "source": [
        "def generate_dataloader(df, tokenizer, max_len, batch_size):\n",
        "    ds = DiffDataset(\n",
        "        contents=df.content.to_numpy(),\n",
        "        labels=df.labels.to_numpy(),\n",
        "        features = df.mean_sentence_len.to_numpy(),\n",
        "        tokenizer=tokenizer,\n",
        "        max_len=max_len,\n",
        "      )\n",
        "    return DataLoader(\n",
        "        ds,\n",
        "        batch_size=batch_size,\n",
        "        num_workers=2\n",
        "      )\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#model_name = 'bert-base-multilingual-uncased'\n",
        "model_name = 'bert-base-uncased'"
      ],
      "metadata": {
        "id": "DsCVKgBLUctr"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "4gJOnD7XlO-1"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "Xfgsled3gC7O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10a8b635-2b9c-4d67-ef0a-10e6d0fde929"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        }
      ],
      "source": [
        "max_len = 256 \n",
        "batch_size = 8\n",
        "\n",
        "train_dataloader = generate_dataloader(df_train, tokenizer, max_len,batch_size)\n",
        "val_dataloader = generate_dataloader(df_val, tokenizer, max_len,batch_size)\n",
        "test_dataloader = generate_dataloader(df_test, tokenizer, max_len,batch_size)\n",
        "\n",
        "data = next(iter(train_dataloader))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aFwYSC2N057o"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SuFyU4DVPb6c"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DiffClassifier(nn.Module):\n",
        "\n",
        "    def __init__(self, n_classes):\n",
        "        super(DiffClassifier, self).__init__()\n",
        "        self.bert = BertModel.from_pretrained(model_name)\n",
        "        # Adding drop out, keeping 90% of the last neurons of the raw BERT model\n",
        "        #self.drop = nn.Dropout(p=0.1)\n",
        "        # The last linear layer for multiclass classification\n",
        "        self.out = nn.Linear(self.bert.config.hidden_size+1, n_classes)\n",
        "  \n",
        "    # Forward propagation function\n",
        "    def forward(self, input_ids, attention_mask, features):\n",
        "        model_outs = self.bert(\n",
        "          input_ids=input_ids,\n",
        "          attention_mask=attention_mask\n",
        "        )\n",
        "        last_hidden_state = model_outs[0]\n",
        "        pooled_output = model_outs[1]\n",
        "\n",
        "        x = torch.cat((pooled_output, features) , dim=1)\n",
        "\n",
        "        return self.out(x)\n"
      ],
      "metadata": {
        "id": "Txzh41fGqKPf"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(diff)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RidqiU54HXR1",
        "outputId": "f200e1ce-1bfd-4e17-b70b-f12897b0a5d2"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = DiffClassifier(len(diff))\n",
        "\n",
        "# Running the classifier on GPU\n",
        "model = model.to(device)\n"
      ],
      "metadata": {
        "id": "PmXqE4EkrBHX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "785e8b4d-82b9-4776-8e84-c7c9ca3b419a"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = data['input_ids'].to(device)\n",
        "attention_mask = data['attention_mask'].to(device)\n",
        "features = data['features'].to(device)\n",
        "print(input_ids.shape)\n",
        "print(attention_mask.shape)\n",
        "print(features.shape)"
      ],
      "metadata": {
        "id": "cjtiveeIRsH2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "963bd3d0-7e5b-41bf-b8c8-781466111ef2"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "features"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FK53V_CXahZN",
        "outputId": "b654d838-48de-4b39-f6ca-d5e4b446d3e6"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[634],\n",
              "        [555],\n",
              "        [695],\n",
              "        [675],\n",
              "        [704],\n",
              "        [834],\n",
              "        [558],\n",
              "        [348]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr=2e-5, \n",
        "                  weight_decay = 0.2,\n",
        "                  correct_bias=False)\n",
        "epochs = 10\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                            num_warmup_steps=0.1,\n",
        "                                            num_training_steps=len(train_dataloader)*epochs)\n",
        "loss_fn = nn.CrossEntropyLoss().to(device)\n"
      ],
      "metadata": {
        "id": "fT-bNR_I4Xdx"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Computing multiclass precision for the outputs of the model\n",
        "def compute_precision(outputs, labels):\n",
        "  op = outputs.cpu()\n",
        "  la = labels.cpu()\n",
        "  _, preds = torch.max(op, dim=1)\n",
        "  # We choose 'weighted' averaging of the precision of each label because it takes into account the imbalance of labels in our tweets dataset\n",
        "  # other viable averaging methods are 'micro'\n",
        "  return torch.tensor(precision_score(la, preds, average='weighted',zero_division=0))"
      ],
      "metadata": {
        "id": "b4X0LoKz4dSs"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, train_dataloader,optimizer,scheduler):\n",
        "\n",
        "        # Reset tracking variables at the beginning of each epoch\n",
        "        precision, correct_predictions, batch_counts = 0, 0, 0\n",
        "        losses = []\n",
        "\n",
        "        # Put the model into the training mode\n",
        "        model.train()\n",
        "\n",
        "  \n",
        "        # For each batch of training data...\n",
        "        for d in train_dataloader:\n",
        "              batch_counts +=1\n",
        "              # Load batch to GPU\n",
        "              input_ids = d[\"input_ids\"].to(device)\n",
        "              attention_mask = d[\"attention_mask\"].to(device)\n",
        "              labels = d[\"labels\"].to(device)\n",
        "              features = d[\"features\"].to(device)\n",
        "\n",
        "              outputs = model(input_ids=input_ids,attention_mask=attention_mask, features=features)\n",
        "              \n",
        "              _, preds = torch.max(outputs, dim=1)\n",
        "              \n",
        "              # Compute loss and accumulate the loss values\n",
        "\n",
        "              loss = loss_fn(outputs, labels)\n",
        "\n",
        "              correct_predictions += torch.sum(preds == labels)\n",
        "              losses.append(loss.item())\n",
        "              precision +=  compute_precision(outputs, labels)\n",
        "            \n",
        "              loss.backward()\n",
        "\n",
        "              # Clip the norm of the gradients to 1.0 to prevent \"exploding gradients\"\n",
        "              torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "              # Update parameters and the learning rate  \n",
        "              optimizer.step()\n",
        "              scheduler.step()\n",
        "              optimizer.zero_grad()\n",
        "          # Accuracy, loss, precision\n",
        "        return correct_predictions.double() / len(df_train), np.mean(losses), precision/batch_counts"
      ],
      "metadata": {
        "id": "TYlrsggO4hcY"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def eval(model, valid_dataloader, loss_fn, device, n):\n",
        "    model = model.eval()\n",
        "\n",
        "\n",
        "    correct_predictions , precision ,batch_counts = 0,0,0\n",
        "    losses = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for d in valid_dataloader:\n",
        "            batch_counts += 1\n",
        "\n",
        "            # Preparing inputs\n",
        "            input_ids = d[\"input_ids\"].to(device)\n",
        "            attention_mask = d[\"attention_mask\"].to(device)\n",
        "            labels = d[\"labels\"].to(device)\n",
        "            features = d[\"features\"].to(device)\n",
        "\n",
        "            # Running inference using the model\n",
        "            outputs = model(\n",
        "                input_ids=input_ids,\n",
        "                attention_mask=attention_mask,\n",
        "                features=features\n",
        "              )\n",
        "            \n",
        "            # Running softmax on the outputs\n",
        "            _, preds = torch.max(outputs, dim=1)\n",
        "\n",
        "            # Computing loss function\n",
        "            loss = loss_fn(outputs, labels)\n",
        "\n",
        "            # Counting the correct occurences\n",
        "            correct_predictions += torch.sum(preds == labels)\n",
        "\n",
        "            # Computing the precision (true positives/true positives + false positives) \n",
        "            # for each class and label, and find their average weighted by support \n",
        "            precision += compute_precision(outputs,labels)\n",
        "\n",
        "            losses.append(loss.item())\n",
        "    # Accuracy, loss, precision \n",
        "    return correct_predictions.double()/n, np.mean(losses), precision/batch_counts "
      ],
      "metadata": {
        "id": "N6uYF4Tg82wa"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = defaultdict(list)\n",
        "b_accuracy = 0\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  \n",
        "  print(f'Epoch {epoch + 1}/{epochs}')\n",
        "  print('-' * 20)\n",
        "\n",
        "  train_acc, train_loss, train_preci = train(\n",
        "        model,\n",
        "        train_dataloader,    \n",
        "        optimizer, \n",
        "        scheduler,\n",
        "      )\n",
        "  print(f\"Train : Loss {train_loss}, Accuracy : {train_acc*100:.2f} %, Precision : {train_preci}\")\n",
        "\n",
        "  history['train_acc'].append(train_acc)\n",
        "  history['train_loss'].append(train_loss)\n",
        "  history['train_precision'].append(train_preci)\n",
        "\n",
        "  val_acc, val_loss, val_preci = eval(\n",
        "        model,\n",
        "        val_dataloader,\n",
        "        loss_fn, \n",
        "        device,\n",
        "        len(df_val),\n",
        "      )\n",
        "\n",
        "  print(f'Val : Loss :{val_loss}, Accuracy : {val_acc*100:.2f} %, Precision : {val_preci}')  \n",
        "  print()\n",
        "\n",
        "  history['val_acc'].append(val_acc)\n",
        "  history['val_loss'].append(val_loss)\n",
        "  history['val_precision'].append(val_preci)\n",
        "  \n",
        "  if val_acc > b_accuracy:\n",
        "    torch.save(model.state_dict(), 'bert_model_baseline.bin')\n",
        "    b_accuracy = val_acc"
      ],
      "metadata": {
        "id": "h8JiTl4u5bWJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "25d9a6d8-2fef-4d48-fbcb-ca0f5741fd8c"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train : Loss 6.791305107228896, Accuracy : 36.86 %, Precision : 0.22496498599439774\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val : Loss :1.8687758445739746, Accuracy : 21.74 %, Precision : 0.16643518518518519\n",
            "\n",
            "Epoch 2/10\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train : Loss 1.9958966818510318, Accuracy : 42.01 %, Precision : 0.35763597105508876\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val : Loss :1.5672621528307598, Accuracy : 52.17 %, Precision : 0.5304232804232805\n",
            "\n",
            "Epoch 3/10\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train : Loss 1.244647739856851, Accuracy : 56.27 %, Precision : 0.6169351073762839\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val : Loss :0.5302216311295828, Accuracy : 86.96 %, Precision : 0.8625000000000002\n",
            "\n",
            "Epoch 4/10\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train : Loss 0.6539925632304421, Accuracy : 81.33 %, Precision : 0.8487336601307186\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val : Loss :0.5726835379997889, Accuracy : 91.30 %, Precision : 0.9027777777777778\n",
            "\n",
            "Epoch 5/10\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-60-60241fe0b903>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-'\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m   train_acc, train_loss, train_preci = train(\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-38-8144e7b63461>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_dataloader, optimizer, scheduler)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m               \u001b[0mcorrect_predictions\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m               \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m               \u001b[0mprecision\u001b[0m \u001b[0;34m+=\u001b[0m  \u001b[0mcompute_precision\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KHKXnnXsgmTJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history['train_acc']"
      ],
      "metadata": {
        "id": "TBMFu1Sw-K5e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4036d43f-4f28-4e45-a031-097216230b8c"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor(0.3686, device='cuda:0', dtype=torch.float64),\n",
              " tensor(0.4201, device='cuda:0', dtype=torch.float64),\n",
              " tensor(0.5627, device='cuda:0', dtype=torch.float64),\n",
              " tensor(0.8133, device='cuda:0', dtype=torch.float64)]"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history['val_acc']"
      ],
      "metadata": {
        "id": "91vf-4r9E8TM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8be0391-b0e6-45cb-a886-d2abd9f1fb02"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor(0.2174, device='cuda:0', dtype=torch.float64),\n",
              " tensor(0.5217, device='cuda:0', dtype=torch.float64),\n",
              " tensor(0.8696, device='cuda:0', dtype=torch.float64),\n",
              " tensor(0.9130, device='cuda:0', dtype=torch.float64)]"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def testing(model, dataloader):\n",
        "  model = model.eval()\n",
        "  \n",
        "  contents = []\n",
        "  predictions = []\n",
        "  prediction_probs = []\n",
        "  real_values = []\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for d in dataloader:\n",
        "\n",
        "      texts = d[\"content\"]\n",
        "      input_ids = d[\"input_ids\"].to(device)\n",
        "      attention_mask = d[\"attention_mask\"].to(device)\n",
        "      labels = d[\"labels\"].to(device)\n",
        "      features = d[\"features\"].to(device)\n",
        "\n",
        "      outputs = model(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask, \n",
        "        features=features\n",
        "      )\n",
        "      _, preds = torch.max(outputs, dim=1)\n",
        "\n",
        "      probs = F.softmax(outputs, dim=1)\n",
        "\n",
        "      contents.extend(texts)\n",
        "      predictions.extend(preds)\n",
        "      prediction_probs.extend(probs)\n",
        "      real_values.extend(labels)\n",
        "\n",
        "  predictions = torch.stack(predictions).cpu()\n",
        "  prediction_probs = torch.stack(prediction_probs).cpu()\n",
        "  real_values = torch.stack(real_values).cpu()\n",
        "  return contents, predictions, prediction_probs, real_values"
      ],
      "metadata": {
        "id": "PtgxKPrHMtN9"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_contents, y_pred, y_pred_probs, y_test = testing(\n",
        "  model,\n",
        "  test_dataloader\n",
        ")"
      ],
      "metadata": {
        "id": "YzKVh2urMLjT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68cc5954-591d-4ae0-9b96-86ca5a1c3395"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, y_pred, target_names=diff))"
      ],
      "metadata": {
        "id": "igCbGvVbMxvj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "692453ee-46b3-410f-9e91-6d9582e85169"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    beginner       0.93      0.91      0.92        43\n",
            "intermediate       0.89      0.84      0.86        38\n",
            "    advanced       0.78      0.85      0.81        33\n",
            "\n",
            "    accuracy                           0.87       114\n",
            "   macro avg       0.87      0.87      0.86       114\n",
            "weighted avg       0.87      0.87      0.87       114\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, y_pred, target_names=diff))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ZH90qd5jApg",
        "outputId": "8b901597-a5c8-4964-d4bb-215e3e22a786"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    beginner       0.84      0.60      0.70        43\n",
            "intermediate       0.49      0.89      0.63        38\n",
            "    advanced       0.54      0.21      0.30        33\n",
            "\n",
            "    accuracy                           0.59       114\n",
            "   macro avg       0.62      0.57      0.55       114\n",
            "weighted avg       0.63      0.59      0.56       114\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_probs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fNBeq2me5t3k",
        "outputId": "d32b395b-40ee-4f8f-bf03-8470d8598c51"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2.6121e-03, 4.9177e-03, 9.9247e-01],\n",
              "        [6.0405e-03, 3.5213e-04, 9.9361e-01],\n",
              "        [2.3634e-08, 1.0000e+00, 3.5735e-07],\n",
              "        [4.1365e-03, 1.5921e-02, 9.7994e-01],\n",
              "        [4.9305e-03, 1.0249e-03, 9.9404e-01],\n",
              "        [5.7801e-10, 1.0000e+00, 1.7950e-08],\n",
              "        [1.5552e-08, 1.0000e+00, 2.6611e-07],\n",
              "        [1.0964e-03, 6.3690e-02, 9.3521e-01],\n",
              "        [1.4420e-03, 3.2691e-02, 9.6587e-01],\n",
              "        [1.7847e-09, 1.0000e+00, 3.0358e-08],\n",
              "        [9.7846e-01, 1.6841e-03, 1.9852e-02],\n",
              "        [8.1820e-01, 3.7795e-02, 1.4401e-01],\n",
              "        [4.1375e-07, 1.0000e+00, 4.3430e-06],\n",
              "        [1.7370e-08, 1.0000e+00, 2.3882e-07],\n",
              "        [6.9046e-03, 2.0564e-01, 7.8746e-01],\n",
              "        [9.7813e-01, 9.3726e-04, 2.0937e-02],\n",
              "        [9.0648e-06, 9.9995e-01, 3.7332e-05],\n",
              "        [5.6625e-02, 1.0848e-02, 9.3253e-01],\n",
              "        [2.1496e-03, 6.3603e-01, 3.6182e-01],\n",
              "        [9.5537e-01, 1.8412e-03, 4.2788e-02],\n",
              "        [9.5649e-01, 1.8540e-02, 2.4967e-02],\n",
              "        [9.6156e-01, 9.1170e-03, 2.9324e-02],\n",
              "        [8.1842e-08, 1.0000e+00, 1.1187e-06],\n",
              "        [1.8564e-06, 9.9998e-01, 1.8123e-05],\n",
              "        [2.7396e-03, 1.1653e-01, 8.8073e-01],\n",
              "        [9.4473e-01, 1.2820e-02, 4.2450e-02],\n",
              "        [9.5423e-01, 7.2085e-03, 3.8563e-02],\n",
              "        [8.0976e-01, 3.7852e-03, 1.8645e-01],\n",
              "        [6.4173e-01, 1.0273e-02, 3.4800e-01],\n",
              "        [6.4174e-09, 1.0000e+00, 1.2101e-07],\n",
              "        [2.4712e-01, 1.1419e-01, 6.3870e-01],\n",
              "        [9.8003e-01, 1.1239e-03, 1.8844e-02],\n",
              "        [7.4207e-01, 2.1921e-01, 3.8718e-02],\n",
              "        [8.9252e-01, 3.8128e-02, 6.9355e-02],\n",
              "        [1.6479e-03, 4.8775e-02, 9.4958e-01],\n",
              "        [6.9974e-03, 1.3195e-01, 8.6105e-01],\n",
              "        [2.8697e-01, 6.1104e-03, 7.0692e-01],\n",
              "        [9.6674e-01, 3.3017e-03, 2.9953e-02],\n",
              "        [3.4478e-04, 9.9906e-01, 5.9436e-04],\n",
              "        [1.4439e-08, 1.0000e+00, 2.2458e-07],\n",
              "        [1.4811e-09, 1.0000e+00, 3.4914e-08],\n",
              "        [7.3809e-10, 1.0000e+00, 1.5923e-08],\n",
              "        [5.6703e-01, 2.9644e-03, 4.3000e-01],\n",
              "        [4.1250e-02, 3.2345e-02, 9.2641e-01],\n",
              "        [9.6881e-01, 1.8830e-04, 3.1003e-02],\n",
              "        [8.7723e-01, 8.6576e-02, 3.6195e-02],\n",
              "        [3.4359e-04, 5.5797e-01, 4.4169e-01],\n",
              "        [1.4025e-02, 1.0482e-03, 9.8493e-01],\n",
              "        [2.5652e-03, 2.0254e-02, 9.7718e-01],\n",
              "        [8.8069e-01, 7.1408e-02, 4.7899e-02],\n",
              "        [9.5971e-01, 6.0910e-03, 3.4202e-02],\n",
              "        [9.4701e-01, 3.9990e-03, 4.8990e-02],\n",
              "        [4.0072e-01, 4.0590e-02, 5.5869e-01],\n",
              "        [9.7331e-01, 8.3137e-03, 1.8375e-02],\n",
              "        [9.6390e-01, 3.5423e-03, 3.2558e-02],\n",
              "        [3.1326e-10, 1.0000e+00, 1.3066e-08],\n",
              "        [2.7909e-03, 3.9125e-03, 9.9330e-01],\n",
              "        [1.7862e-03, 4.0186e-02, 9.5803e-01],\n",
              "        [2.5046e-01, 4.5934e-01, 2.9020e-01],\n",
              "        [9.4983e-01, 2.7254e-03, 4.7443e-02],\n",
              "        [7.5394e-01, 2.1653e-01, 2.9527e-02],\n",
              "        [1.1289e-09, 1.0000e+00, 2.8176e-08],\n",
              "        [3.6082e-01, 2.8349e-02, 6.1084e-01],\n",
              "        [6.3946e-08, 1.0000e+00, 7.1198e-07],\n",
              "        [8.5563e-01, 1.1262e-01, 3.1751e-02],\n",
              "        [8.8614e-01, 6.7332e-03, 1.0713e-01],\n",
              "        [5.6675e-08, 1.0000e+00, 5.8460e-07],\n",
              "        [6.5388e-10, 1.0000e+00, 1.5362e-08],\n",
              "        [2.5053e-08, 1.0000e+00, 2.7281e-07],\n",
              "        [9.8487e-01, 1.2615e-03, 1.3872e-02],\n",
              "        [1.0835e-07, 1.0000e+00, 1.3724e-06],\n",
              "        [7.7232e-01, 1.9742e-01, 3.0255e-02],\n",
              "        [2.7763e-01, 1.2966e-03, 7.2108e-01],\n",
              "        [2.4181e-03, 7.7268e-03, 9.8986e-01],\n",
              "        [2.0270e-08, 1.0000e+00, 3.8991e-07],\n",
              "        [9.7006e-01, 1.0262e-02, 1.9678e-02],\n",
              "        [3.5833e-03, 3.0946e-03, 9.9332e-01],\n",
              "        [2.2234e-01, 5.2181e-02, 7.2548e-01],\n",
              "        [1.9828e-02, 5.5877e-03, 9.7458e-01],\n",
              "        [9.4638e-01, 2.6306e-02, 2.7313e-02],\n",
              "        [3.4211e-02, 2.0853e-01, 7.5726e-01],\n",
              "        [1.7327e-08, 1.0000e+00, 1.9676e-07],\n",
              "        [2.2304e-09, 1.0000e+00, 5.2822e-08],\n",
              "        [1.4027e-02, 3.2808e-04, 9.8565e-01],\n",
              "        [4.7015e-10, 1.0000e+00, 1.7170e-08],\n",
              "        [3.9430e-02, 8.9474e-01, 6.5831e-02],\n",
              "        [4.4823e-03, 1.8999e-03, 9.9362e-01],\n",
              "        [1.7289e-02, 9.8312e-03, 9.7288e-01],\n",
              "        [7.9771e-10, 1.0000e+00, 2.0215e-08],\n",
              "        [9.1075e-01, 5.5301e-02, 3.3951e-02],\n",
              "        [9.1482e-01, 5.7464e-02, 2.7715e-02],\n",
              "        [5.3351e-02, 4.3806e-02, 9.0284e-01],\n",
              "        [9.6225e-01, 1.5806e-02, 2.1948e-02],\n",
              "        [9.2296e-01, 2.7721e-02, 4.9323e-02],\n",
              "        [4.5739e-07, 1.0000e+00, 3.9654e-06],\n",
              "        [8.8531e-01, 8.4149e-02, 3.0537e-02],\n",
              "        [4.9737e-01, 3.2986e-02, 4.6964e-01],\n",
              "        [9.4998e-01, 2.7773e-02, 2.2246e-02],\n",
              "        [7.5548e-03, 1.2619e-02, 9.7983e-01],\n",
              "        [1.0700e-02, 5.9986e-04, 9.8870e-01],\n",
              "        [9.8322e-08, 1.0000e+00, 9.2793e-07],\n",
              "        [7.9666e-01, 1.3062e-01, 7.2721e-02],\n",
              "        [4.5428e-11, 1.0000e+00, 2.3034e-09],\n",
              "        [9.4264e-01, 1.9425e-02, 3.7935e-02],\n",
              "        [8.7304e-01, 4.3492e-02, 8.3464e-02],\n",
              "        [2.9464e-03, 3.5893e-03, 9.9346e-01],\n",
              "        [2.5726e-01, 5.7331e-03, 7.3701e-01],\n",
              "        [1.1199e-01, 3.6135e-02, 8.5187e-01],\n",
              "        [1.0626e-06, 9.9999e-01, 8.8298e-06],\n",
              "        [9.8123e-01, 6.2673e-04, 1.8144e-02],\n",
              "        [3.1474e-03, 2.7051e-02, 9.6980e-01],\n",
              "        [1.3329e-07, 1.0000e+00, 1.2834e-06],\n",
              "        [9.7368e-01, 2.1956e-03, 2.4129e-02],\n",
              "        [7.0572e-08, 1.0000e+00, 8.5859e-07]])"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out_df = pd.DataFrame()\n",
        "out_df['content'] = y_contents\n",
        "out_df['true_label'] = y_test\n",
        "out_df['pred_label'] = y_pred"
      ],
      "metadata": {
        "id": "hhsZpo3r5j2s"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "Od3k1bHW6ECV",
        "outputId": "84e8014a-123b-4cca-a734-3a199d6198d1"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               content  true_label  pred_label\n",
              "0    What is it like to look at the very last of To...           2           2\n",
              "1    SeaWorld has suffered an collapse in profits a...           2           2\n",
              "2    On the market square in Rjukan stands a statue...           1           1\n",
              "3    The world shares him and London claims him but...           2           2\n",
              "4    The regulation eight hours in the office is Th...           2           2\n",
              "..                                                 ...         ...         ...\n",
              "109  Some cities have Lima has black They fly in gr...           0           0\n",
              "110  David Cameron has declared a in the Scottish i...           2           2\n",
              "111  Clay Cockrell is sitting in his of ce across t...           1           1\n",
              "112  Police and intelligence agencies around the wo...           0           0\n",
              "113  Do you want your child to be good at play for ...           1           1\n",
              "\n",
              "[114 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-81300ab5-bb10-4a2a-b246-d66ac84932a2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>content</th>\n",
              "      <th>true_label</th>\n",
              "      <th>pred_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What is it like to look at the very last of To...</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>SeaWorld has suffered an collapse in profits a...</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>On the market square in Rjukan stands a statue...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The world shares him and London claims him but...</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The regulation eight hours in the office is Th...</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>109</th>\n",
              "      <td>Some cities have Lima has black They fly in gr...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>110</th>\n",
              "      <td>David Cameron has declared a in the Scottish i...</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111</th>\n",
              "      <td>Clay Cockrell is sitting in his of ce across t...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>112</th>\n",
              "      <td>Police and intelligence agencies around the wo...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>113</th>\n",
              "      <td>Do you want your child to be good at play for ...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>114 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-81300ab5-bb10-4a2a-b246-d66ac84932a2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-81300ab5-bb10-4a2a-b246-d66ac84932a2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-81300ab5-bb10-4a2a-b246-d66ac84932a2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out_df.to_csv('out_BERT_256_simple features.csv')"
      ],
      "metadata": {
        "id": "AjPhwZHc6HUv"
      },
      "execution_count": 68,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "c7348d43abd18e49db4462acea6057bd7f94ba9fb1f8e5afcc42e7585456bcc3"
      }
    },
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "cdada0b541f94eddaf1b0e9f23a9a9b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b717ec4370de402e8263a38ca4dd30aa",
              "IPY_MODEL_1e0d8d6adc5e432dbbae1762f0140e99",
              "IPY_MODEL_f37e55a4cc3b4e479beb4a07fbd49b11"
            ],
            "layout": "IPY_MODEL_b4da6277f04c41a58443a8876e9badf6"
          }
        },
        "b717ec4370de402e8263a38ca4dd30aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_44206c0d371f4ac0aa03731e1b968258",
            "placeholder": "​",
            "style": "IPY_MODEL_9bc9f30cde044beabebacbaa860d5dc9",
            "value": "100%"
          }
        },
        "1e0d8d6adc5e432dbbae1762f0140e99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f90adc8bb7c4be998836153a3898a54",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7f4d43fb3f7a4893ad43eaefde975e70",
            "value": 1
          }
        },
        "f37e55a4cc3b4e479beb4a07fbd49b11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9fbb0d43e5b34456855f5a2825a7fda3",
            "placeholder": "​",
            "style": "IPY_MODEL_51aeceaa410e4b24a7595e5d569eb5ff",
            "value": " 1/1 [00:00&lt;00:00, 50.48it/s]"
          }
        },
        "b4da6277f04c41a58443a8876e9badf6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44206c0d371f4ac0aa03731e1b968258": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9bc9f30cde044beabebacbaa860d5dc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9f90adc8bb7c4be998836153a3898a54": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f4d43fb3f7a4893ad43eaefde975e70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9fbb0d43e5b34456855f5a2825a7fda3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51aeceaa410e4b24a7595e5d569eb5ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}